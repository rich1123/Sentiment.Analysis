{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Tesla Wooed by $1 Billion Missouri Package for Cybertruck Plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla shares pop after Credit Suisse upgrades stock says company will increase electric car lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla shares jump after hours as Goldman initiates with buy rating sees rally above $800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Analysts are bullish on stocks like Tesla Netflix and Zoom as earnings season gets underway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>What to watch today: Dow set to jump at open as earnings seasons kicks off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla's secret batteries aim to rework the math for electric cars and the grid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Ex-Google CEO Eric Schmidt: Employers shouldn't force workers to return 'under fear of losing their jobs'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Elon Musk appears to be selling more California properties after pledging to 'own no house'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Coronavirus live updates: Japan's Takeda treatment trial could start in July global cases top 4.3 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Stocks making the biggest moves in the premarket: 3M Cisco SmileDirectClub Starbucks &amp; more</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     source  \\\n",
       "0    2020-04-14  Bloomberg   \n",
       "1    2020-04-14  CNBC        \n",
       "2    2020-04-14  CNBC        \n",
       "3    2020-04-14  CNBC        \n",
       "4    2020-04-14  CNBC        \n",
       "..          ...   ...        \n",
       "162  2020-05-14  CNBC        \n",
       "163  2020-05-14  CNBC        \n",
       "164  2020-05-14  CNBC        \n",
       "165  2020-05-14  CNBC        \n",
       "166  2020-05-14  CNBC        \n",
       "\n",
       "                                                                                                      headline  \n",
       "0    Tesla Wooed by $1 Billion Missouri Package for Cybertruck Plant                                            \n",
       "1    Tesla shares pop after Credit Suisse upgrades stock says company will increase electric car lead           \n",
       "2    Tesla shares jump after hours as Goldman initiates with buy rating sees rally above $800                   \n",
       "3    Analysts are bullish on stocks like Tesla Netflix and Zoom as earnings season gets underway                \n",
       "4    What to watch today: Dow set to jump at open as earnings seasons kicks off                                 \n",
       "..                                                                          ...                                 \n",
       "162  Tesla's secret batteries aim to rework the math for electric cars and the grid                             \n",
       "163  Ex-Google CEO Eric Schmidt: Employers shouldn't force workers to return 'under fear of losing their jobs'  \n",
       "164  Elon Musk appears to be selling more California properties after pledging to 'own no house'                \n",
       "165  Coronavirus live updates: Japan's Takeda treatment trial could start in July global cases top 4.3 million  \n",
       "166  Stocks making the biggest moves in the premarket: 3M Cisco SmileDirectClub Starbucks & more                \n",
       "\n",
       "[167 rows x 3 columns]"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load headlines2.csv\n",
    "path2 = os.path.join(os.path.abspath('headlines2.csv'))\n",
    "df_headlines = pd.read_csv(path2)\n",
    "df_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>headline</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Tesla Wooed by $1 Billion Missouri Package for Cybertruck Plant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla shares pop after Credit Suisse upgrades stock says company will increase electric car lead</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla shares jump after hours as Goldman initiates with buy rating sees rally above $800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Analysts are bullish on stocks like Tesla Netflix and Zoom as earnings season gets underway</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>What to watch today: Dow set to jump at open as earnings seasons kicks off</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla's secret batteries aim to rework the math for electric cars and the grid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Ex-Google CEO Eric Schmidt: Employers shouldn't force workers to return 'under fear of losing their jobs'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Elon Musk appears to be selling more California properties after pledging to 'own no house'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Coronavirus live updates: Japan's Takeda treatment trial could start in July global cases top 4.3 million</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Stocks making the biggest moves in the premarket: 3M Cisco SmileDirectClub Starbucks &amp; more</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     source  \\\n",
       "0    2020-04-14  Bloomberg   \n",
       "1    2020-04-14  CNBC        \n",
       "2    2020-04-14  CNBC        \n",
       "3    2020-04-14  CNBC        \n",
       "4    2020-04-14  CNBC        \n",
       "..          ...   ...        \n",
       "162  2020-05-14  CNBC        \n",
       "163  2020-05-14  CNBC        \n",
       "164  2020-05-14  CNBC        \n",
       "165  2020-05-14  CNBC        \n",
       "166  2020-05-14  CNBC        \n",
       "\n",
       "                                                                                                      headline  \\\n",
       "0    Tesla Wooed by $1 Billion Missouri Package for Cybertruck Plant                                             \n",
       "1    Tesla shares pop after Credit Suisse upgrades stock says company will increase electric car lead            \n",
       "2    Tesla shares jump after hours as Goldman initiates with buy rating sees rally above $800                    \n",
       "3    Analysts are bullish on stocks like Tesla Netflix and Zoom as earnings season gets underway                 \n",
       "4    What to watch today: Dow set to jump at open as earnings seasons kicks off                                  \n",
       "..                                                                          ...                                  \n",
       "162  Tesla's secret batteries aim to rework the math for electric cars and the grid                              \n",
       "163  Ex-Google CEO Eric Schmidt: Employers shouldn't force workers to return 'under fear of losing their jobs'   \n",
       "164  Elon Musk appears to be selling more California properties after pledging to 'own no house'                 \n",
       "165  Coronavirus live updates: Japan's Takeda treatment trial could start in July global cases top 4.3 million   \n",
       "166  Stocks making the biggest moves in the premarket: 3M Cisco SmileDirectClub Starbucks & more                 \n",
       "\n",
       "     score  \n",
       "0   NaN     \n",
       "1   NaN     \n",
       "2   NaN     \n",
       "3   NaN     \n",
       "4   NaN     \n",
       "..   ..     \n",
       "162 NaN     \n",
       "163 NaN     \n",
       "164 NaN     \n",
       "165 NaN     \n",
       "166 NaN     \n",
       "\n",
       "[167 rows x 4 columns]"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty column to store sentiment scores per article\n",
    "df_headlines['score'] = np.nan\n",
    "df_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/asamra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tesla', 'Wooed', 'by', '$', '1', 'Billion', 'Missouri', 'Package', 'for', 'Cybertruck', 'Plant']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize essentially splits a sentence into words\n",
    "headline_0 = word_tokenize(df_headlines['headline'][0])\n",
    "print(headline_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/asamra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Stop words are words that provide no sentiment meaning\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append ':' to stop_words list\n",
    "stop_words.append(':')\n",
    "#print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tesla', 'Wooed', '$', '1', 'Billion', 'Missouri', 'Package', 'Cybertruck', 'Plant']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from headline at index 0\n",
    "filtered_headline_0 = []\n",
    "for word in headline_0:\n",
    "    if word not in stop_words:\n",
    "        filtered_headline_0.append(word)\n",
    "print(filtered_headline_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/asamra/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists for each type of word: positive, negative and neurtral\n",
    "headline_0_pos = []\n",
    "headline_0_neg = []\n",
    "headline_0_neu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in algorithm determines sentiment of word\n",
    "# https://stackoverflow.com/questions/43646877/python-extract-positive-words-from-a-string-using-sentiment-vader/43647056\n",
    "for word in filtered_headline_0:\n",
    "    if (sid.polarity_scores(word)['compound']) >= 0.5:\n",
    "        headline_0_pos.append(word)\n",
    "    elif (sid.polarity_scores(word)['compound']) <= -0.5:\n",
    "        headline_0_neg.append(word)\n",
    "    else:\n",
    "        headline_0_neu.append(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(headline_0_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(headline_0_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tesla', 'Wooed', '$', '1', 'Billion', 'Missouri', 'Package', 'Cybertruck', 'Plant']\n"
     ]
    }
   ],
   "source": [
    "print(headline_0_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a formula to determine how to assign an article \n",
    "#score_0 = ((1/3)*len(headline_0_pos) - (1/3)*len(headline_0_neg))/len(filtered_headline_0)\n",
    "\"\"\"if len(headline_0_neu) >= len(headline_0_pos) and len(headline_0_neu) >= len(headline_0_neg):\n",
    "    score_0 = 0\n",
    "elif len(headline_0_pos) > len(headline_0_neg):\n",
    "    score_0 = 1\n",
    "else:\n",
    "    score_0 = -1\"\"\"\n",
    "\n",
    "score_0 = round((1*len(headline_0_pos) - 1*len(headline_0_neg) + 0*len(headline_0_neu))/len(filtered_headline_0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(score_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, we perform the operations above for every row in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2020-04-14 0.0\n",
      "1 2020-04-14 0.0\n",
      "2 2020-04-14 0.0\n",
      "3 2020-04-14 0.0\n",
      "4 2020-04-14 0.0\n",
      "5 2020-04-14 0.0\n",
      "6 2020-04-14 0.0\n",
      "7 2020-04-14 0.0\n",
      "8 2020-04-14 0.0\n",
      "9 2020-04-14 0.0\n",
      "10 2020-04-14 0.0\n",
      "11 2020-04-14 0.0\n",
      "12 2020-04-15 0.0\n",
      "13 2020-04-15 0.0\n",
      "14 2020-04-15 0.0\n",
      "15 2020-04-15 0.0\n",
      "16 2020-04-15 0.0\n",
      "17 2020-04-15 0.0\n",
      "18 2020-04-15 0.0\n",
      "19 2020-04-15 0.0\n",
      "20 2020-04-16 0.0\n",
      "21 2020-04-17 0.0\n",
      "22 2020-04-17 0.0\n",
      "23 2020-04-21 0.0\n",
      "24 2020-04-22 0.0\n",
      "25 2020-04-22 0.0\n",
      "26 2020-04-22 -0.09\n",
      "27 2020-04-22 0.0\n",
      "28 2020-04-22 0.0\n",
      "29 2020-04-22 -0.08\n",
      "30 2020-04-23 0.0\n",
      "31 2020-04-24 0.0\n",
      "32 2020-04-24 0.0\n",
      "33 2020-04-24 0.0\n",
      "34 2020-04-25 0.0\n",
      "35 2020-04-25 0.0\n",
      "36 2020-04-25 0.0\n",
      "37 2020-04-26 0.0\n",
      "38 2020-04-27 0.0\n",
      "39 2020-04-27 0.0\n",
      "40 2020-04-27 0.0\n",
      "41 2020-04-27 0.0\n",
      "42 2020-04-27 0.0\n",
      "43 2020-04-27 0.0\n",
      "44 2020-04-27 0.0\n",
      "45 2020-04-28 0.0\n",
      "46 2020-04-28 0.0\n",
      "47 2020-04-28 0.0\n",
      "48 2020-04-28 0.0\n",
      "49 2020-04-28 0.0\n",
      "50 2020-04-28 0.0\n",
      "51 2020-04-28 0.0\n",
      "52 2020-04-28 0.0\n",
      "53 2020-04-28 0.0\n",
      "54 2020-04-29 0.0\n",
      "55 2020-04-29 0.0\n",
      "56 2020-04-29 0.0\n",
      "57 2020-04-29 0.0\n",
      "58 2020-04-29 -0.09\n",
      "59 2020-04-29 0.0\n",
      "60 2020-04-29 0.08\n",
      "61 2020-04-29 0.0\n",
      "62 2020-04-29 0.0\n",
      "63 2020-04-29 0.0\n",
      "64 2020-04-30 0.0\n",
      "65 2020-04-30 0.0\n",
      "66 2020-04-30 0.0\n",
      "67 2020-04-30 0.0\n",
      "68 2020-04-30 0.0\n",
      "69 2020-04-30 0.0\n",
      "70 2020-04-30 0.0\n",
      "71 2020-04-30 -0.08\n",
      "72 2020-04-30 0.0\n",
      "73 2020-04-30 -0.08\n",
      "74 2020-04-30 0.0\n",
      "75 2020-05-01 0.0\n",
      "76 2020-05-01 -0.11\n",
      "77 2020-05-01 0.0\n",
      "78 2020-05-01 0.0\n",
      "79 2020-05-01 0.0\n",
      "80 2020-05-01 0.0\n",
      "81 2020-05-01 0.0\n",
      "82 2020-05-01 0.0\n",
      "83 2020-05-02 0.0\n",
      "84 2020-05-02 0.0\n",
      "85 2020-05-02 0.0\n",
      "86 2020-05-02 0.0\n",
      "87 2020-05-04 0.0\n",
      "88 2020-05-04 0.0\n",
      "89 2020-05-04 0.0\n",
      "90 2020-05-04 0.0\n",
      "91 2020-05-04 0.0\n",
      "92 2020-05-05 0.08\n",
      "93 2020-05-05 0.0\n",
      "94 2020-05-05 0.0\n",
      "95 2020-05-06 0.0\n",
      "96 2020-05-07 0.0\n",
      "97 2020-05-07 0.0\n",
      "98 2020-05-07 0.0\n",
      "99 2020-05-07 0.0\n",
      "100 2020-05-07 0.0\n",
      "101 2020-05-07 0.0\n",
      "102 2020-05-07 0.0\n",
      "103 2020-05-08 0.0\n",
      "104 2020-05-08 0.0\n",
      "105 2020-05-08 0.0\n",
      "106 2020-05-08 0.0\n",
      "107 2020-05-08 0.0\n",
      "108 2020-05-08 0.0\n",
      "109 2020-05-08 0.0\n",
      "110 2020-05-08 0.0\n",
      "111 2020-05-08 0.0\n",
      "112 2020-05-08 0.0\n",
      "113 2020-05-08 0.0\n",
      "114 2020-05-09 0.0\n",
      "115 2020-05-09 0.0\n",
      "116 2020-05-09 0.0\n",
      "117 2020-05-09 0.0\n",
      "118 2020-05-09 0.0\n",
      "119 2020-05-09 0.0\n",
      "120 2020-05-10 0.0\n",
      "121 2020-05-10 -0.06\n",
      "122 2020-05-11 0.0\n",
      "123 2020-05-11 0.0\n",
      "124 2020-05-11 0.0\n",
      "125 2020-05-11 0.0\n",
      "126 2020-05-11 0.0\n",
      "127 2020-05-11 0.11\n",
      "128 2020-05-11 0.0\n",
      "129 2020-05-11 0.0\n",
      "130 2020-05-11 0.0\n",
      "131 2020-05-11 0.0\n",
      "132 2020-05-11 0.0\n",
      "133 2020-05-11 0.0\n",
      "134 2020-05-11 0.0\n",
      "135 2020-05-11 0.0\n",
      "136 2020-05-11 0.0\n",
      "137 2020-05-11 0.0\n",
      "138 2020-05-12 0.0\n",
      "139 2020-05-12 0.0\n",
      "140 2020-05-12 0.0\n",
      "141 2020-05-12 0.0\n",
      "142 2020-05-12 0.0\n",
      "143 2020-05-12 0.0\n",
      "144 2020-05-12 0.0\n",
      "145 2020-05-12 0.0\n",
      "146 2020-05-12 0.0\n",
      "147 2020-05-12 0.0\n",
      "148 2020-05-12 0.0\n",
      "149 2020-05-13 0.0\n",
      "150 2020-05-13 0.0\n",
      "151 2020-05-13 0.14\n",
      "152 2020-05-13 -0.06\n",
      "153 2020-05-13 0.0\n",
      "154 2020-05-13 0.0\n",
      "155 2020-05-13 -0.07\n",
      "156 2020-05-13 0.0\n",
      "157 2020-05-13 0.0\n",
      "158 2020-05-14 0.0\n",
      "159 2020-05-14 0.0\n",
      "160 2020-05-14 0.0\n",
      "161 2020-05-14 0.0\n",
      "162 2020-05-14 0.0\n",
      "163 2020-05-14 0.0\n",
      "164 2020-05-14 0.0\n",
      "165 2020-05-14 0.0\n",
      "166 2020-05-14 0.0\n"
     ]
    }
   ],
   "source": [
    "# Iterate through df_headlines to determine sentiment score for each headline\n",
    "for index, row in df_headlines.iterrows():\n",
    "    headline_tokenized = word_tokenize(row['headline'])\n",
    "    filtered_headline = []\n",
    "    for word in headline_tokenized:\n",
    "        if word not in stop_words:\n",
    "            filtered_headline.append(word)\n",
    "    #print(filtered_headline)\n",
    "    headline_pos = []\n",
    "    headline_neg = []\n",
    "    headline_neu = []\n",
    "    for word in filtered_headline:\n",
    "        if (sid.polarity_scores(word)['compound']) >= 0.5:\n",
    "            headline_pos.append(word)\n",
    "        elif (sid.polarity_scores(word)['compound']) <= -0.5:\n",
    "            headline_neg.append(word)\n",
    "        else:\n",
    "            headline_neu.append(word)\n",
    "    \n",
    "    score = round((1*len(headline_pos) - 1*len(headline_neg) + 0*len(headline_neu))/len(filtered_headline),2)\n",
    "    \n",
    "    \"\"\"if len(headline_neu) >= len(headline_pos) and len(headline_neu) >= len(headline_neg):\n",
    "        score = 0\n",
    "    elif len(headline_pos) > len(headline_neg):\n",
    "        score = 1\n",
    "    else:\n",
    "        score = -1\"\"\"\n",
    "        \n",
    "    \"\"\"if len(headline_pos) > len(headline_neg):\n",
    "        score = 1\n",
    "    elif len(headline_neg) > len(headline_pos):\n",
    "        score = -1\n",
    "    else:\n",
    "        score = 0\"\"\"\n",
    "    #print(len(headline_neu), len(headline_neg), len(headline_pos))\n",
    "    df_headlines.at[index,'score'] = score\n",
    "    print(index, row['date'], score)\n",
    "    #print(len(headline_pos), len(headline_neg), len(headline_neu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>headline</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Tesla Wooed by $1 Billion Missouri Package for Cybertruck Plant</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla shares pop after Credit Suisse upgrades stock says company will increase electric car lead</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla shares jump after hours as Goldman initiates with buy rating sees rally above $800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Analysts are bullish on stocks like Tesla Netflix and Zoom as earnings season gets underway</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>What to watch today: Dow set to jump at open as earnings seasons kicks off</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla's secret batteries aim to rework the math for electric cars and the grid</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Ex-Google CEO Eric Schmidt: Employers shouldn't force workers to return 'under fear of losing their jobs'</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Elon Musk appears to be selling more California properties after pledging to 'own no house'</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Coronavirus live updates: Japan's Takeda treatment trial could start in July global cases top 4.3 million</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Stocks making the biggest moves in the premarket: 3M Cisco SmileDirectClub Starbucks &amp; more</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     source  \\\n",
       "0    2020-04-14  Bloomberg   \n",
       "1    2020-04-14  CNBC        \n",
       "2    2020-04-14  CNBC        \n",
       "3    2020-04-14  CNBC        \n",
       "4    2020-04-14  CNBC        \n",
       "..          ...   ...        \n",
       "162  2020-05-14  CNBC        \n",
       "163  2020-05-14  CNBC        \n",
       "164  2020-05-14  CNBC        \n",
       "165  2020-05-14  CNBC        \n",
       "166  2020-05-14  CNBC        \n",
       "\n",
       "                                                                                                      headline  \\\n",
       "0    Tesla Wooed by $1 Billion Missouri Package for Cybertruck Plant                                             \n",
       "1    Tesla shares pop after Credit Suisse upgrades stock says company will increase electric car lead            \n",
       "2    Tesla shares jump after hours as Goldman initiates with buy rating sees rally above $800                    \n",
       "3    Analysts are bullish on stocks like Tesla Netflix and Zoom as earnings season gets underway                 \n",
       "4    What to watch today: Dow set to jump at open as earnings seasons kicks off                                  \n",
       "..                                                                          ...                                  \n",
       "162  Tesla's secret batteries aim to rework the math for electric cars and the grid                              \n",
       "163  Ex-Google CEO Eric Schmidt: Employers shouldn't force workers to return 'under fear of losing their jobs'   \n",
       "164  Elon Musk appears to be selling more California properties after pledging to 'own no house'                 \n",
       "165  Coronavirus live updates: Japan's Takeda treatment trial could start in July global cases top 4.3 million   \n",
       "166  Stocks making the biggest moves in the premarket: 3M Cisco SmileDirectClub Starbucks & more                 \n",
       "\n",
       "     score  \n",
       "0    0.0    \n",
       "1    0.0    \n",
       "2    0.0    \n",
       "3    0.0    \n",
       "4    0.0    \n",
       "..   ...    \n",
       "162  0.0    \n",
       "163  0.0    \n",
       "164  0.0    \n",
       "165  0.0    \n",
       "166  0.0    \n",
       "\n",
       "[167 rows x 4 columns]"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        2020-04-22                                                                                   \n",
       "source      CNBC                                                                                         \n",
       "headline    Chamath Palihapitiya: We've 'ripped the philosophical band-aid off' on universal basic income\n",
       "score       0                                                                                            \n",
       "Name: 28, dtype: object"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See score for a particular location to check for accuracy\n",
    "df_headlines.iloc[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of df_headlines to perform grouping operations\n",
    "df_headlines2 = df_headlines.copy()\n",
    "df_headlines2.drop(['source', 'headline'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_group = df_headlines2.groupby('date')\n",
    "#df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for name, group in df_headlines2.groupby('date'):\\n    daily_pos = len(group[group['score'] == 1])\\n    daily_neg = len(group[group['score'] == -1])\\n    daily_neu = len(group[group['score'] == 0])\\n    print(name, daily_pos, daily_neg, daily_neu)\""
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find daily score for scores of 1, -1, 0; not for continuous variable\n",
    "# https://stackoverflow.com/questions/61806725/iterate-over-a-pandas-data-frame-or-groupby-object?noredirect=1#comment109323032_61806725\n",
    "\"\"\"for name, group in df_headlines2.groupby('date'):\n",
    "    daily_pos = len(group[group['score'] == 1])\n",
    "    daily_neg = len(group[group['score'] == -1])\n",
    "    daily_neu = len(group[group['score'] == 0])\n",
    "    print(name, daily_pos, daily_neg, daily_neu)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-14</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-16</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-17</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-21</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-22</th>\n",
       "      <td>-0.028333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-23</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-24</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-25</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-26</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-27</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>-0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30</th>\n",
       "      <td>-0.014545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>-0.013750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-02</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-04</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-05</th>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-06</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-07</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-08</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-09</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-10</th>\n",
       "      <td>-0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-11</th>\n",
       "      <td>0.006875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-12</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            daily_score\n",
       "date                   \n",
       "2020-04-14  0.000000   \n",
       "2020-04-15  0.000000   \n",
       "2020-04-16  0.000000   \n",
       "2020-04-17  0.000000   \n",
       "2020-04-21  0.000000   \n",
       "2020-04-22 -0.028333   \n",
       "2020-04-23  0.000000   \n",
       "2020-04-24  0.000000   \n",
       "2020-04-25  0.000000   \n",
       "2020-04-26  0.000000   \n",
       "2020-04-27  0.000000   \n",
       "2020-04-28  0.000000   \n",
       "2020-04-29 -0.001000   \n",
       "2020-04-30 -0.014545   \n",
       "2020-05-01 -0.013750   \n",
       "2020-05-02  0.000000   \n",
       "2020-05-04  0.000000   \n",
       "2020-05-05  0.026667   \n",
       "2020-05-06  0.000000   \n",
       "2020-05-07  0.000000   \n",
       "2020-05-08  0.000000   \n",
       "2020-05-09  0.000000   \n",
       "2020-05-10 -0.030000   \n",
       "2020-05-11  0.006875   \n",
       "2020-05-12  0.000000   \n",
       "2020-05-13  0.001111   \n",
       "2020-05-14  0.000000   "
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group headlines by date and calculate average score\n",
    "df_group = df_headlines2.groupby('date').mean()\n",
    "df_group.rename(columns = {'score': 'daily_score'}, inplace = True)\n",
    "df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group.to_csv('sentiment_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
